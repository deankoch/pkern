% !TeX root = RJwrapper.tex
\title{blitzkrig: An R Package for Fast Geostatistics with Kronecker Covariances}
\author{by Dean Koch, Subhash Lele, and Robert Crabtree}

\maketitle

\abstract{%
We introduce in this paper a new R package, called \CRANpkg{blitzkrig}, for modelling two-dimensional stationary Gaussian Processes. The package assumes gridded data and a special covariance structure wherein the joint covariance matrix V can factored using Kronecker products. This simplifies several important modelling equations, including the likelihood function, the generalized least squares equation, and the kriging predictor and variance equations. Our package offers computationally lean implementations of these equations (and more). We demonstrate its kriging functionality with predictions on the Meuse soils datasets, and also report on a benchmark experiment for computation time that shows improvements of several orders of magnitude compared to four major alternative R packages for spatial kriging.
}

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

The second-order stationary Gaussian Process (SGP) plays a central role in modern analysis of spatial data. In geostatistics it underlies several important techniques of inference and prediction (Chiles and Delfiner 2012), including generalized least squares and kriging. We see it also in engineering and computer experiments with surrogate models (Gramacy 2016), in machine learning prediction algorithms (Rasmussen and Williams 2006), and in probabilistic models for ecological systems (Koch, Lewis, and Lele 2021), among many other applications.

In the SGP model, the joint probability distribution for \(n\) points \(z_k\), with coordinates \(x_k\), \(y_k\), is multivariate Gaussian, and its variance-covariance matrix \(V\) is generated by a function \(C\) of the separation vector between points \(V_{ij} = C ( x_i - x_j, y_i - y_j )\) (Cressie 2015). One of the charms of SGP theory is the simplicity in analytic expressions for things like likelihood, conditional expectation, and least squares estimates, all of which involve \(V\) and its sub-matrices.

However, \(V\) is a major headache for computer programmers. The number of entries in this matrix is \(n^2\), so as sample sizes grow large, seemingly routine matrix expressions become surprisingly difficult to evaluate. For large enough \(n\), readers will find that either \(V\) is too large to fit in computer memory, or the order-\(n^3\) complexity of its factorization is prohibitively slow, or both (Lindgren, Rue, and Lindström 2011).

These are major obstacles to software implementations of SGP, particularly when it comes to kriging. Kriging workflows with popular packages like \CRANpkg{gstat}, \CRANpkg{geoR}, and \CRANpkg{fields} can become so slow as to be unworkable (or even fail entirely due to out-of-memory errors) when the number of point locations of interest are large in number, as we will see in the \protect\hyperlink{computations}{Computations} section.

This practical upper limit on sample sizes with conventional models motivates us to introduce a new package, \CRANpkg{blitzkrig}, whose implementation of the SGP is designed around Kronecker covariances on grid data, for improved computational efficiency. The computational ceiling is still there, but it is extended much higher. \CRANpkg{blitzkrig} offers:

\begin{itemize}
\tightlist
\item
  Optimized functions for likelihood, GLS, kriging, and simulation
\item
  Flexible parametric covariance structures supporting anisotropy
\item
  Simple beginner-friendly workflows for down-scaling
\item
  Compatibility with data objects from \CRANpkg{raster}, \CRANpkg{terra}, and \CRANpkg{sf} packages
\end{itemize}

The likelihood function is particularly important here because it will enable modelers to adapt the methods in \CRANpkg{blitzkrig} as an engine for handling autocorrelation in more complex nonlinear spatial models, such as in the simulation of integro-difference equations. In fact, this package is built from code that was originall written for such a model, in a study on mountain pine beetle outbreaks (Koch, Lele, and Lewis 2020).

We illustrate the speed-up offered by \CRANpkg{blitzkrig} in the \protect\hyperlink{computations}{Computations} section, with a comparison of computation times on a variety of ordinary kriging problems. This follows the \protect\hyperlink{kriging-example}{Kriging Example} section, where we present a detailed demonstration of a universal kriging workflow on the Meuse soils dataset. First we review some related tools and introducing the modelling approach that makes \CRANpkg{blitzkrig} unique.

\hypertarget{background}{%
\subsection{Background}\label{background}}

One strategy for computation with \(V\) on large-\(n\) problems is parallelization. The \CRANpkg{bigGP} (Paciorek et al. 2015) and the \CRANpkg{laGP} (Gramacy 2016) packages, for example, distribute the task of block factorization to multiple linked processes. This can speed likelihood calculations by several orders of magnitude in large-\(n\) examples.

However, these packages have steep learning curves, and are intended for high-memory, many-core computers. \CRANpkg{blitzkrig} instead aims to be simple to learn and operate, with a memory footprint suitable for use on ordinary desktop computers.

Large-\(n\) solutions of this type usually make use of local approximations to the desired covariance function, with the goal of introducing sparsity in \(V\) or its inverse (the precision matrix). Examples include: covariance tapering and fixed rank kriging, like in \CRANpkg{LatticeKrig} (Nychka et al. 2016) and \CRANpkg{FRK} (Zammit-Mangion and Cressie 2021); Markov Random Field approximations (Lindgren, Rue, and Lindström 2011), and Bayesian approximations like R-INLA (Lindgren and Rue 2015), \CRANpkg{laGP} (Gramacy 2016), and \CRANpkg{spBayes} Finley, Banerjee, and E.Gelfand (2015).

The approach in \CRANpkg{blitzkrig} is unusual in that it computes exact likelihood (and kriging predictions) but also supports long-tailed (non-compact) covariance functions, including the very common Gaussian covariance function. The dense covariance matrices \(V\) that result from this choice would normally be problematic, but our package does not rely on sparsity.

Instead it uses an algebraic shortcut that emerges for gridded layouts and certain covariance functions, called \emph{Kronecker covariances} (Koch, Lele, and Lewis 2020; Drton, Kuriki, and Hoff 2021). This shortcut also pops up in auto-regression (Martin 1979) and separable space-time SGPs (Genton 2007), but despite its elegant computational properties (Van Loan 2000) we rarely see it used in purely spatial problems like ordinary kriging.

CRAN lists a number of alternatives for fitting exact SGP models (R. Bivand and Nowosad 2022), but three stand out for their scope, maturity, and quality of documentation: The \CRANpkg{gstat} package for variogram-based geostatistical modeling (E. J. Pebesma 2004; R. S. Bivand, Pebesma, and Gómez-Rubio 2013); The \CRANpkg{geoR} package, which supports variogram, likelihood, and Bayesian techniques (Ribeiro Jr and Diggle 1999; Diggle and Ribeiro 2007), and \CRANpkg{fields} a feature-rich interpolation package by Douglas Nychka et al. (2021) for SGPs and spline models.

The RandomFields package by Schlather et al. (2015) also deserves mention, but is no longer in active development and not currently listed on CRAN. We included the most recently archived version of this package (2022-05-04) in the comparisons of the \protect\hyperlink{computations}{Computations} section, along with the most recent major release of \CRANpkg{gstat}, \CRANpkg{geoR}, and \CRANpkg{fields} (as of 2022-09-04).

\begin{table}

\caption{\label{tab:cfun-table-latex}A list of one-dimensional correlation functions available in blitzkrig. Kronecker covariances are constructed from the product of a pair of these functions, one receiving the $x$ separation distance as its argument, and the other the $y$ distance. Normalization constants are omitted for brevity, and $K_p$ denotes the order-$p$ Bessel function of the second kind (where $p$ is a shape parameter).}
\centering
\fontsize{9}{11}\selectfont
\begin{tabular}[t]{llll}
\toprule
code & name & alias & $c\left( \Delta \right)$\\
\midrule
exp & Exponential & - & $\exp\left( -\Delta \right)$\\
gau & Gaussian & Squared-Exponential, or Stable Kernel & $\exp\left( -\Delta^2 \right)$\\
gex & Gamma-Exponential & Power-Exponential & $\exp\left( -\Delta^p \right)$\\
mat & Mat\'ern & Whittle-Mat\'ern & $\Delta^p K_p\left( \Delta \right)$\\
sph & Spherical & - & $1 - (3/2)\Delta + (1/2)\Delta^3$\\
\bottomrule
\end{tabular}
\end{table}

\hypertarget{model}{%
\subsection{Model}\label{model}}

\CRANpkg{blitzkrig} models a response data vector \(z\) of point values \(z_k\) (for \(k=1,\dots n\)) as an observation of the \(n\)-dimensional random vector \(Z \sim \text{N} \left( X\beta, V \right)\). This splits \(z\) into a deterministic trend component and a random spatial component.

The trend is represented by the expected value \(X\beta\), where \(X\) is a known covariate data matrix and \(\beta\) an unknown vector of coefficients. The spatial component is represented by a two-dimensional (2d) covariance function \(C\) which generates the covariance matrix \(V\).

In \CRANpkg{blitzkrig}, the covariance function is constructed using the product of two one-dimensional components \(c_x\) and \(c_y\). These are functions of the \(x\) and \(y\) component distances, \(\Delta_x\) and \(\Delta_y\), and the covariance function has the form:
\begin{equation}
C \left( \Delta_x, \Delta_y \right) = \sigma^2 c_x \left( \Delta_x \right) c_y \left( \Delta_y \right) + \epsilon 1_{ \{ \Delta_x = \Delta_y = 0 \}}. \label{eq:covfun}
\end{equation}

where component distances are scaled by range parameters \(\rho_x\) and \(\rho_y\),
\begin{equation}
\Delta_x = \frac{ \lvert x_i - x_j \rvert }{ \rho_x } \quad \text{and} \quad \Delta_y = \frac{ \lvert y_i - y_j \rvert }{ \rho_y }. \label{eq:dfun}
\end{equation}

We call this a \emph{Kronecker covariance} because when the observed data lie on a regular grid (and we assume they do), the matrix \(V - \epsilon I\) takes the form of a Kronecker product. Any pair of correlation functions can be used, and their parameters may take on different values in the \(x\) and \(y\) directions.
Table \ref{tab:cfun-table-latex}
lists all functional forms for \(c\) currently implemented in \CRANpkg{blitzkrig}.

Parameters \(\sigma\) and \(\epsilon\) are the partial sill, and nugget variance, respectively. The nugget variance can be understood here to represent aspatial measurement error, whereas the partial sill, and range parameters describe the variance of points and the spatial profile of correlations between them.

For a more complete description these parameters and their various interpretations, see Cressie (2015). In particular, it is helpful to understand their role in defining a graphical diagnostic known as the semi-variogram curve, some examples of which are found towards the end of the \protect\hyperlink{kriging-example}{Kriging Example} section.

\hypertarget{kriging-example}{%
\section{Kriging Example}\label{kriging-example}}

\CRANpkg{blitzkrig} is primarily a kriging package, so we will demonstrate its core features in a point interpolation problem. Those familiar with the documentation for the \CRANpkg{sp} and \CRANpkg{gstat} packages will recognize the Meuse dataset, which appears in many R code examples and in the vignette by E. Pebesma (2022).

This is a survey of soil heavy metal concentrations the Meuse river floodplain in the Netherlands, introduced by Burrough, McDonnell, and Lloyd (2015) and later reproduced as part of the \CRANpkg{sp} package by E. J. Pebesma and Bivand (2005). In this example we will interpolate zinc concentration while adjusting for a linear covariate, distance to river.

The SGP is a model for a multivariate normal random variable, so users should always begin by considering whether their data fits this assumption closely enough. In our case, log-transforming the concentration data produces a response variable that more closely resembles a sample from the expected distribution. These log-zinc values been loaded already in the \CRANpkg{sf} points data-frame named \texttt{pts}. Figure \ref{fig:meuse-png} (left) shows how the 155 observations are positioned relative to the river.

\begin{verbatim}
# snap log zinc data to grid of specified resolution
g = pkern_snap(pts, g=list(gres=c(y=50, x=50)))
\end{verbatim}

\begin{verbatim}
#> maximum snapping distance: 33.2640947569598
\end{verbatim}

\begin{figure}
\includegraphics[width=0.5\linewidth]{kcov_files/figure-latex/meuse-png-1} \includegraphics[width=0.5\linewidth]{kcov_files/figure-latex/meuse-png-2} \caption{Zinc concentrations (in log parts per billion) from the Meuse dataset, a soil survey on the floodplain of the Meuse River (left). These data are snapped to a grid for use with blitzkrig (right)}\label{fig:meuse-png}
\end{figure}

\CRANpkg{blitzkrig} only supports points lying on a regular grid. Irregularly spaced points like the Meuse data must be first snapped to such a grid. This is a matter of selecting a resolution sufficiently fine as to produce an acceptably small positional error. In the code above, we used \texttt{pkern\_snap} to specify a resolution of 50 x 50 metres, creating a grid of dimensions 78 x 56 (rows x columns) with extent covering the Meuse point sample (Figure \ref{fig:meuse-png}, right). At this resolution most positional errors are in the range of 10-25 metres distance, which is good enough for the demonstration here.

\hypertarget{ordinary-kriging}{%
\subsection{Ordinary Kriging}\label{ordinary-kriging}}

The new gridded version of the data is now in the format expected by the \CRANpkg{blitzkrig}'s core modelling functions. A covariates data matrix \texttt{X} may optionally be supplied, as we do later, to account for linear trends. First, by way of comparison, we will ignore covariates and fit a spatially constant trend.

\texttt{pkern\_fit} attempts to automatically find maximum likelihood estimators (MLEs) for the mean and covariance parameters by numerically optimizing the full joint likelihood for all observed points in \texttt{g}, using R's \texttt{base::optim}.

\begin{verbatim}
# fit the covariance model and mean
fit_result_ok = pkern_fit(g, quiet=TRUE)
\end{verbatim}

The default covariance function implemented in \texttt{pkern\_fit} is the isotropic Gaussian, but a variety of alternatives are available
(see Table \ref{tab:cfun-table-latex} and the \protect\hyperlink{model}{Model} section). Sensible defaults for initial values and bounds are set automatically based on the sample variance and grid dimensions.

To interpolate observed data, pass the covariance parameters (argument \texttt{pars}) and a grid containing the observed data (argument \texttt{g\_obs}) to \texttt{pkern\_cmean}. This populates all grid points in \texttt{g\_obs} with values from the kriging prediction equation (including at observed points). Variance is computed separately, but the calling syntax is the same apart from argument \texttt{out=\textquotesingle{}v\textquotesingle{}}.

\begin{verbatim}
# compute conditional mean and variance 
z_ok = pkern_cmean(g_obs=g, pars=fit_result_ok[['pars']])
z_ok_var = pkern_cmean(g_obs=g, pars=fit_result_ok[['pars']], out='v', quiet=TRUE)
\end{verbatim}

\begin{figure}
\includegraphics[width=0.5\linewidth]{kcov_files/figure-latex/meuse-ok-pred-png-1} \includegraphics[width=0.5\linewidth]{kcov_files/figure-latex/meuse-ok-pred-png-2} \caption{Ordinary kriging prediction and variance heatmaps generated by blitzkrig for the Meuse example. Predictions are generated for the entire grid, but are masked here to show detail in areas nearest the observed points.}\label{fig:meuse-ok-pred-png}
\end{figure}

Figure \ref{fig:meuse-ok-pred-png} displays the output, masked to a neighbourhood of the observed data. Here we have requested predictions over the same grid that was used for fitting. Users can request any output grid they like, by snapping the observed data to it and passing it to \texttt{pkern\_cmean} in argument \texttt{g\_obs}. At the end of this section we will predict over a grid at much finer resolution.

The workflow up to this point has been ordinary kriging (OK), as we did not use any covariates to adjust for linear trends. We will do that now, by including distance to river (along with its square root) as example predictors, and re-fitting the model to demonstrate universal kriging (UK).

\hypertarget{universal-kriging}{%
\subsection{Universal Kriging}\label{universal-kriging}}

To include covariates in a model fit, simply pass a matrix \texttt{X} of covariate values at the observed point locations in your call to \texttt{pkern\_fit}. For prediction, the \texttt{X} argument in \texttt{pkern\_cmean} should include all of the output grid point locations.

Covariate data (rows) must be supplied in the same order as the response data in \texttt{g}. In the code below we construct the full matrix \texttt{X} by using \texttt{pkern\_coords} to export the grid point locations to an \texttt{sf} points data-frame in the correct order, then use \texttt{sf::st\_distance} to compute distances to a line geometry representing the middle of the river.

\begin{verbatim}
# measure distances for every point in the grid
river_dist = sf::st_distance(pkern_coords(g, out='sf'), meuse_list[['river_line']])
\end{verbatim}

\begin{verbatim}
#> processing 4368 grid points...
\end{verbatim}

\begin{verbatim}
# include both distance and its square root
river_dist = units::drop_units(river_dist)
X = scale(cbind(river_dist, sqrt(river_dist)))

# find the subset of predictors at observed response locations
is_obs = !is.na(g[['gval']])
\end{verbatim}

The UK workflow can now proceed like OK, except with \texttt{X} passed to \texttt{pkern\_fit} and \texttt{pkern\_cmean}.

\begin{verbatim}
# fit the covariance model again with X
fit_result_uk = pkern_fit(g_obs=g, X=X[is_obs,], quiet=TRUE)

# compute conditional mean and variance (supply all distances in X this time)
z_uk = pkern_cmean(g, fit_result_uk[['pars']], X=X)
z_uk_var = pkern_cmean(g, fit_result_uk[['pars']], X=X, out='v', quiet=TRUE)
\end{verbatim}

These functions account for \texttt{X} by calling \texttt{pkern\_GLS} automatically in the course of calculations to de-trend the response, \(z\). Given a set of MLE covariance parameters, \texttt{pkern\_GLS} estimates the trend \(X\beta\) using the generalized least squares (GLS) expression for the effects vector \(\hat{\beta}\).

\begin{verbatim}
# use GLS to estimate the spatially varying trend 
z_lm = pkern_GLS(g, fit_result_uk[['pars']], X=X, out='z')
\end{verbatim}

\begin{figure}
\includegraphics[width=0.33\linewidth]{kcov_files/figure-latex/meuse-uk-pred-png-1} \includegraphics[width=0.33\linewidth]{kcov_files/figure-latex/meuse-uk-pred-png-2} \includegraphics[width=0.33\linewidth]{kcov_files/figure-latex/meuse-uk-pred-png-3} \caption{Universal kriging predictions and variance generated by blitzkrig for the Meuse example. The response variable (log zinc concentration) is de-trended using a linear predictor (left) based on distance to river and its square root during model fitting, resulting in more detail in kriging predictions (middle), and a decrease in kriging variance (right)}\label{fig:meuse-uk-pred-png}
\end{figure}

We called \texttt{pkern\_GLS} by hand in the code above to produce the image in the left pane of Figure \ref{fig:meuse-uk-pred-png}, showing the values \(X\hat{\beta}\) over the entire output grid. The middle and right panes show the resulting UK predictions and variance.

\hypertarget{diagnostics}{%
\subsection{Diagnostics}\label{diagnostics}}

Assuming the covariance model is a good fit to the data, kriging theory guarantees that \texttt{pkern\_cmean} will return the best linear unbiased predictor for grid \texttt{g\_obs}, in the sense of minimizing kriging variance.

To find the best fitting model for their data, users are encouraged to seek out informative covariates to include in \texttt{X}, and to check model fitting diagnostics for problems that would impact predictions. \CRANpkg{blitzkrig} provides two visual diagnostics in the functions \texttt{pkern\_plot\_pars} and \texttt{pkern\_plot\_semi}.

\begin{figure}[!htb]
\includegraphics[width=0.5\linewidth]{kcov_files/figure-latex/meuse-vg-png-1} \includegraphics[width=0.5\linewidth]{kcov_files/figure-latex/meuse-vg-png-2} \includegraphics[width=0.5\linewidth]{kcov_files/figure-latex/meuse-vg-png-3} \includegraphics[width=0.5\linewidth]{kcov_files/figure-latex/meuse-vg-png-4} \caption{Fitted covariance models from kriging on the Meuse dataset, visualized in two ways: On the left, estimated semi-variogram values (circles) are plotted next to model predictions (blue curves). On the right, a heatmap displays covariances with respect to the central point. The top two plots show the fitted OK model. The bottom two plots show the UK model, where removing a linear trend from the response data has resulted in lower variance and a smaller range.}\label{fig:meuse-vg-png}
\end{figure}

The output of \texttt{pkern\_fit} includes a list of covariance parameters. Any such parameter list can be visualized using \texttt{pkern\_plot\_pars}. This shows the footprint of covariances between any given point and its surrounding points and indicates the level of smoothing to be expected in predictions. Another type of visualization, the semi-variogram, can be plotted with \texttt{pkern\_plot\_semi}. Various estimators for the semi-variogram are implemented in \texttt{pkern\_sample\_vg}. These generate a point cloud of sample semi-variances, estimated directly from the data, that can be compared visually with the theoretical curve obtained via MLE.

Diagnostic plots from the OK and UK workflows are shown together for comparison in Figure \ref{fig:meuse-vg-png}. Accounting for distance to the river has a dramatic effect on the fitted covariance model. The UK model estimates a much lower variance than OK, and favors a much smaller effective range (or spatial scale of correlations). This leads to more spatial detail in the kriging predictions from UK.

The initial values and bounds used in fitting covariance parameters can be found in the output of \texttt{pkern\_fit} (data-frame \texttt{bds}). We encourage users to understand these settings, and to be on the lookout for common problems with fitting, such as parameters converging to a bound, or not moving from their initial values. Both can indicate problems of model-misspecification, or simply a poor choice of initial values.

\hypertarget{anistropic-models}{%
\subsection{Anistropic Models}\label{anistropic-models}}

Another way of improving model fit is to explore covariance functions with more flexibility than the default isotropic Gaussian. The term \emph{isotropic} refers to radial symmetry in \(C\) (equal distance implying equal covariance), and \emph{anisotropic} refers to its absence. \CRANpkg{blitzkrig} supports models of both kinds.

The following code fits two examples to the Meuse data; The first is a Gaussian covariance with anisotropy, and the second a Matérn product covariance (Koch, Lele, and Lewis 2020).

\begin{verbatim}
# fit a 2 + 2 parameter Gaussian covariance with anisotropy
fit_result_uk_gau = pkern_fit(g_obs=g, X=X[is_obs,], iso=FALSE, quiet=TRUE)

# fit a 2 + 4 parameter product Matern
fit_result_uk_mat = pkern_fit(g_obs=g, X=X[is_obs,], pars='mat', iso=FALSE, quiet=TRUE)
\end{verbatim}

The \texttt{iso=FALSE} argument allows \(c_x\) and \(c_y\) to take on different parameters, whereas the default \texttt{iso=TRUE} forces \(c_x=c_y\). The \texttt{pars=\textquotesingle{}mat\textquotesingle{}} argument is shorthand for \texttt{pars=c(y=\textquotesingle{}mat\textquotesingle{},\ x=\textquotesingle{}mat\textquotesingle{})}. It specifies that \(c_x\) and \(c_y\) should both be Matérn functions.

\begin{figure}[!htb]
\includegraphics[width=0.19\linewidth]{kcov_files/figure-latex/meuse-alt-fit-1} \includegraphics[width=0.19\linewidth]{kcov_files/figure-latex/meuse-alt-fit-2} \includegraphics[width=0.19\linewidth]{kcov_files/figure-latex/meuse-alt-fit-3} \includegraphics[width=0.19\linewidth]{kcov_files/figure-latex/meuse-alt-fit-4} \includegraphics[width=0.19\linewidth]{kcov_files/figure-latex/meuse-alt-fit-5} \caption{Five examples of anisotropic covariance structures fitted to the Meuse data. As in the previous figure, darker pixels indicate stronger correlation with the central point. From left to right, these are the Kronecker covariances formed by setting both $c_x$ and $c_y$ equal to "gau", "mat", "gxp", "sph", and "exp" models, respectively.}\label{fig:meuse-alt-fit}
\end{figure}

The anisotropic Gaussian function has one more parameter than its isotropic counterpart, since it allows the two range parameters \(\rho_x\) and \(\rho_y\) to vary independently. The Matérn product function adds two more shape parameters, controlling the degree of kurtosis in two directions. The fitted parameters from these two models are visualized as the first two heatmaps on the left of Figure \ref{fig:meuse-alt-fit}, together with models for three other choices of \texttt{pars}.

The Gaussian is the only isotropic model in \CRANpkg{blitzkrig}. The product Matérn function (\texttt{fit\_result\_uk\_mat} above), for example, does \emph{not} generalize the more common 2d (isotropic) Matérn function. It does however approach the Gaussian as \(p \to \inf\) (Koch, Lewis, and Lele 2020).

Other choices of \(c_x\), \(c_x\) lead to a variety of other types of anisotropy, but always with a directionality oriented along one or both of the coordinate axes. Differently oriented data could be modeled by estimating the direction of anisotropy in a preliminary analysis (\emph{eg.} by the method of Koch, Lele, and Lewis 2020) then rotating the observed point locations by this angle prior to snapping. For simplicity, we skip this step here.

Anisotropic covariance functions impart complexity, in the form of new parameters, but also flexibility. Flexibility is a double-edged sword. It can improve a model by more closely aligning it with reality, or it can worsen it by enabling over-fitting, which leads to underestimates of uncertainty and poor predictions.

\hypertarget{cross-validation}{%
\subsection{Cross-validation}\label{cross-validation}}

\begin{figure}[!bht]
\includegraphics[width=0.33\linewidth]{kcov_files/figure-latex/meuse-alt-pred-png-1} \includegraphics[width=0.33\linewidth]{kcov_files/figure-latex/meuse-alt-pred-png-2} \includegraphics[width=0.33\linewidth]{kcov_files/figure-latex/meuse-alt-pred-png-3} \caption{Universal kriging results for the Meuse example using a product Matérn covariance function. The semi-variogram (left) is now a ribbon plot, showing a range values at a given distance due to anisotropy. The middle and right panes show the model predictions and their variance.}\label{fig:meuse-alt-pred-png}
\end{figure}

Figure \ref{fig:meuse-alt-pred-png} shows the semi-variogram, predictions, and variance from the Matérn product model fitted in the previous section. The predictions have more spatial complexity compared to the isotropic UK model fitted earlier on, and variance has decreased slightly. Are we over-fitting? One way to check is through cross-validation (CV).

In CV, we withhold a subset of the data (a hold-out set, or fold) during model fitting, and then come back to it later as a reference to compare predictions. If we have an over-fitting problem, the model is likely to predict well on the training locations, but poorly on the hold-out locations. The hold-out error gives an indication of what to expect when predicting at an unseen locations.

We performed a 5-fold cross-validation experiment, by dividing the 155 observed Meuse points (randomly) into five folds, each of size n=31. For each fold, we fitted all four models to the complementary subset of the data (size n=124), then computed the mean squared prediction error on the hold-out set for log-zinc (MSPE) and its back-transformed version, MSPEb (see the \protect\hyperlink{back-transforming}{Back-transforming} section below).

\begin{table}

\caption{\label{tab:cv-table-latex}Estimates of the root mean squared prediction error on the Meuse dataset for log zinc (rMSPE) and its back-transformed values (rMSPEb) in a 25 X 5-fold cross-validation (CV) experiment. Results are reported for the four kriging models presented earlier, illustrating a progression of improvement as we add covariates and refine the covariance model.}
\centering
\fontsize{9}{11}\selectfont
\begin{tabular}[t]{lllrrrr}
\toprule
name & covariance & isotropic & covariates & parameters & rMSPE & rMSPEb\\
\midrule
fit\_result\_ok & gau x gau & TRUE & 0 & 5 & 0.3147218 & 312.3033\\
fit\_result\_uk & gau x gau & TRUE & 2 & 7 & 0.2872748 & 160.6523\\
fit\_result\_uk\_gau & gau x gau & FALSE & 2 & 8 & 0.2767657 & 156.5372\\
fit\_result\_uk\_mat & mat x mat & FALSE & 2 & 10 & 0.2641235 & 151.3025\\
\bottomrule
\end{tabular}
\end{table}

As these statistics were sensitive to the choice of partition, we repeated the process 25 times and averaged the results. They are reported in Table
\ref{tab:cv-table-latex}. Lower scores indicate better predictive performance and a better fitting model. We found a progression of improvements as we added complexity: starting with our baseline model (\texttt{fit\_result\_ok}), then adding covariates (\texttt{fit\_result\_uk}), introducing anisotropy (\texttt{fit\_result\_uk\_gau}) and, finally, introducing additional flexibility in covariance shape (\texttt{fit\_result\_uk\_mat}).

\hypertarget{back-transforming}{%
\subsection{Back-transforming}\label{back-transforming}}

If predictions are required on the original scale (ppb, instead of its logarithm), users may think to simply take the exponential of the kriging predictions vector \texttt{z\_uk}. However this leads to underestimates of the (random) variable \(\exp(z)\) (by Jensen's inequality), so we recommend adding one half the kriging variance to \texttt{z\_uk} before exponentiating (Cressie 2015). Note that this particular bias-adjustment is specific to the log-transformation.

\hypertarget{computations}{%
\section{Computations}\label{computations}}

This final section explores the computational bottlenecks that can make kriging slow, and that techniques that \CRANpkg{blitzkrig} uses to circumvent them. The core idea is to rewrite the matrix \(V - \epsilon I\) as a Kronecker product (see the \protect\hyperlink{model}{Model} section), so that operations involving sub-matrices of \(V\) can be simplified.

Two sub-matrices are particularly important in this context. The first is the \(n_o \times n_o\) covariance \(V_o\), for the \(n_o\) observed points. \(V_o\) has to be generated (its entries calculated), then factorized, so that products of the form \(V_o^{-1} z\) can be calculated. This happens in many routine spatial statistical operations - including likelihood, GLS, kriging equations, and conditional simulation - and it the reason they become computationally intensive for large \(n_o\).

The second important sub-matrix is the \(n_p \times n_o\) cross-covariance \(V_p\), between the observed locations and the \(n_p\) unseen prediction locations. \(n_p\) can be very large, particularly when a gridded output is needed, making products with \(V_p\) expensive both in terms of computation time and memory use. Such products appear in both the kriging prediction and variance equations.

\CRANpkg{blitzkrig} generates the entries of \(V_o\) and \(V_p\) directly from the Kronecker product factorization of \(V - \epsilon I\). This speeds construction time for \(V_o\) and \(V_p\), and, more importantly, it enables the package to multiply a vector by \(V_p\) without having to explicitly build \(V_p\) in computer memory.

\hypertarget{benchmark-comparisons}{%
\subsection{Benchmark Comparisons}\label{benchmark-comparisons}}

To illustrate the speed of \CRANpkg{blitzkrig} we timed computations for the Meuse OK exercise presented in the \protect\hyperlink{kriging-example}{Kriging Example} section, repeating it several times over a range of output resolutions (varying \(n_p\)) and recording median evaluation times in five repetitions using \CRANpkg{microbenchmark}.

For comparison we also tested four popular R packages mentioned in the introduction, \CRANpkg{gstat}, \CRANpkg{geoR}, \CRANpkg{fields}, and RandomFields, all using the same isotropic Gaussian model fitted with default settings. To get a range of observed sample sizes (\(n_o\)) values we repeated this process with five other point datasets, one on ozone concentration, and four on forest density.

The ozone data are included as the object \texttt{ChicagoO3} in the \CRANpkg{fields} package (Douglas Nychka et al. 2021) and appear frequently in its example code. They are Environmental Protection Agency recordings of average ozone concentration in the air at \(n_o=20\) Chicago-area stations in 1987.

\begin{figure}[htb]
\includegraphics[width=0.33\linewidth]{kcov_files/figure-latex/treed-png-1} \includegraphics[width=0.33\linewidth]{kcov_files/figure-latex/treed-png-2} \includegraphics[width=0.33\linewidth]{kcov_files/figure-latex/treed-png-3} \caption{A 1021 x 1349 raster on forest density in central BC, Canada (left) is up-scaled to produce a much coarser resolution version with dimensions 32 x 43 (middle). blitzkrig can rapidly downscale rasters like these. In a UK model adjusting for elevation, the predictions at right (at original resolution) were generated in less than a second.}\label{fig:treed-png}
\end{figure}

The forest data come from Canada-wide estimates of forest characteristics by Beaudoin et al. (2018). Estimates of areal tree cover (\%) for the province of British Columbia (BC) are re-published in \CRANpkg{rasterbc} as (raster) tiles, each containing around one million data points. We created 4 much smaller example datasets by taking sub-samples of points from a tile in Central BC (Figure \ref{fig:treed-png}, left).

For one of the forest sub-samples (which we call treed) we picked one thousand points at random. For the others we sampled points at regular intervals, so that the sub-samples themselves formed rasters. These up-scaled datasets are named treed\_88, treed\_352, treed\_1376, with the suffix indicating \(n_o\). Figure \ref{fig:treed-png} (middle) shows the largest.

The three raster examples are special in that the observed point sets form complete grids. They contain no \texttt{NA}s. The three irregularly sampled point sets (ozone, Meuse, and treed) are examples of the incomplete data case. All but around 0.1\% of the points in the treed grid are \texttt{NA}, and in the (snapped) ozone and Meuse grids, empty, un-sampled spaces are filled with \texttt{NA}s (see Figure \ref{fig:meuse-png}, right).

\hypertarget{complete-data}{%
\subsection{Complete Data}\label{complete-data}}

This distinction between complete and incomplete is important because both \(V - \epsilon I\) and \(V_o - \epsilon I\) have Kronecker product factorizations in the complete case, and this makes \(V_o\) much easier to deal with. The result is big performance improvements in \CRANpkg{blitzkrig} on large \(n_o\) problems, particularly in evaluations of the likelihood.

\begin{figure}
\centering
\includegraphics{kcov_files/figure-latex/bench-fit-png-1.pdf}
\caption{\label{fig:bench-fit-png}Evaluation times for likelihood-based OK model fitting to example data with a range of sample sizes (\(n_o\)). Cases where the observed data form a complete regular grid are indicated by dashed lines, whereas incomplete cases are indicated with solid lines. The likelihood function in blitzkrig is optimized for the complete case, leading to faster performance. Two additional up-scaled treed datasets (with \(n_o\) 5440 and 21632) were tested to show large-\(n_o\) behaviour in blitzkrig.}
\end{figure}

The improvement is illustrated in Figure \ref{fig:bench-fit-png}, which plots evaluation time against \(n_o\) for likelihood-based model fitting. We excluded \CRANpkg{gstat} from this comparison because it uses variograms (instead of MLE) to parametrize covariance. The other packages all follow a similar trajectory of rising computation times, with the exception of \CRANpkg{blitzkrig} in the complete data case (dotted lines). Speedy likelihood function evaluations by \CRANpkg{blitzkrig} led to faster fitting times for large \(n_o\).

In a log-log plot like Figure \ref{fig:bench-fit-png}, a linear trend with slope \(p\) reflects a complexity power law with exponent \(p\). What is noteworthy here is in the large-\(n_o\) behavior, which shows a similar \(p\) for all packages except \CRANpkg{blitzkrig} on complete examples, where it is faster than the rest by a factor that grows \emph{exponentially} with \(n_o\). These differences reflects the rate-limiting operation of factoring \(V_o\). In \CRANpkg{blitzkrig} its algorithmic complexity is \(O( n_o^3 )\) for incomplete data, and closer to \(O(n_o^{3/2})\) for complete data.

The performance advantage of \CRANpkg{blitzkrig} on complete grids is not limited to kriging-related problems. We can expect similar improvements in computation time for any application of likelihood, GLS, or simulations from SGPs. Note that the completeness requirement is strict - any number of \texttt{NA}s in the data grid means the grid is incomplete

\hypertarget{prediction-and-variance}{%
\subsection{Prediction and Variance}\label{prediction-and-variance}}

After model fitting we timed evaluations of the kriging prediction and variance equations for ten prediction grids, ranging in size from \(8 \times 11\) (\(n_p=88\)) to \(4084 \times 5396\) (\(n_p>\) 22 million). To limit the total length of the experiment, the function calls for each package were halted (timed-out) at around two minutes.

For \CRANpkg{blitzkrig} and \CRANpkg{fields}, we timed kriging prediction and variance separately. In \CRANpkg{gstat} and \CRANpkg{geoR}, both are returned from a single function call, so we only recorded the combined time. In RandomFields, variance was unavailable at the time of writing, so we recorded only prediction time.

\begin{figure}
\centering
\includegraphics{kcov_files/figure-latex/bench-pred-png-1.pdf}
\caption{\label{fig:bench-pred-png}A comparison of computational performance in kriging as a function of the number of point prediction, \(n_p\). Dashed lines indicate prediction time on its own, and solid lines indicate time to compute both predictions and variance. Panels separate results from six example, where top row examples are incomplete (grids containing NAs), and bottom row examples are complete. As \(n_o\) grows large, blitzkrig shows relatively fast performance, particularly on complete datasets.}
\end{figure}

The times are plotted in Figure \ref{fig:bench-pred-png} as a function of prediction grid size, \(n_p\). Results from each data example are shown separately in two rows of three panels - the top three show results from the incomplete cases, and the bottom three from the complete cases. One thing that is obvious right away is the relative speed of prediction (dashed lines) compared to variance and prediction (solid lines). This is because in the variance equation we must multiply \(V_p\) by a matrix, whereas in prediction we multiply it by a vector (increasing complexity by a factor of \(n_o\)). This makes RandomFields, \CRANpkg{fields}, and \CRANpkg{blitzkrig} stand in out the large \(n_p\) results for having fast prediction-only methods.

Even with incomplete data, the prediction method of \CRANpkg{blitzkrig} was the fastest by far on all but the smallest \(n_p\) and \(n_o\) examples. As we saw with likelihood, the relative speed-up increases with \(n_o\), and by \(n_o=1000\) it is nearly two orders of magnitude faster than the next fastest method for large \(n_p\) problems. Variance was also faster with large \(n_o\) on the incomplete examples, but to a lesser extent.

With complete data, prediction times were even faster. For example, kriging from the treed\_1376 points onto a \(1021 \times 1349\) grid took less than half a second in \CRANpkg{blitzkrig}, whereas the next fastest package (\CRANpkg{fields}) required 90 seconds.

\CRANpkg{blitzkrig} is naturally suited down-scaling with complete data, and the addition of covariates and anisotropy introduces little additional computational complexity in prediction. For example, it took less than three seconds to create the \(1021 \times 1349\) UK output for the treed\_1376 example in Figure \ref{fig:treed-png} (right) using the anisotropic Gaussian covariance, and elevation, along with its square root, as covariates. Half of this time was used in fitting and half in prediction.

Variance computations were also much improved in the complete case, where the combined variance and prediction times for \CRANpkg{blitzkrig} were faster than any other package by 1-2 orders of magnitude in all but the smallest \(n_p\) examples.

\CRANpkg{blitzkrig} computes the variance in an unusual way (for both complete and incomplete problems). Instead of multiplying \(V_p\) by the \(n_o \times n_o\) matrix \(V_o^{-1}\), we multiply it be the eigen-vectors of \(V_o\) in a (length-\(n_o\)) loop, combining results as it goes. This is slower than matrix multiplication but it greatly reduces computer memory demands on problems with \(n_o\) and \(n_p\) both large, as we avoid ever having to write \(V_p\) or the product \(V_p V_o^{-1}\) entirely in memory during kriging.

\hypertarget{summary}{%
\section{Summary}\label{summary}}

Kronecker covariances are common enough in geostatistics. We see them everywhere in the form of Gaussian covariance functions, and separable space-time models. Nevertheless, we are unaware of any other CRAN R package for SGP models that factors the \emph{spatial} covariance \(V\) into a Kronecker product, as we do in \CRANpkg{blitzkrig}.

This factorization leads to huge computational advantages in evaluating likelihood and kriging equations (among other things), as we saw in Figures \ref{fig:bench-fit-png} and \ref{fig:bench-pred-png}), with speed-ups of 1-3 orders of magnitude on problems with hundreds to thousands of observed points. This, for example, makes it feasible to downscale a raster onto a grid of several million points in seconds, using a statistically principled, MLE-based OK or UK model.

A fast interpolation tool like this could supplant methods like inverse distance weighting and Voronoi tiling, which, despite their bias issues, are often considered as reasonable fill-ins for when kriging is computationally impractical.

\CRANpkg{blitzkrig} gets its performance edge through restrictions on covariance and point layout, but we nevertheless think it has wide applicability. Users can simply snap irregular points to a reasonably large grid, as we did in the Meuse example. And while some important covariance functions like the 2d Matérn are excluded, the alternatives provided will be flexible enough approximations in many cases (Koch, Lele, and Lewis 2020).

In specializing for Kronecker covariance, \CRANpkg{blitzkrig} raises the upper limits for practical sample sizes and resolutions in SGP-based analysis, providing a more interactive and less frustrating user experience for analysts.

\hypertarget{references}{%
\section*{References}\label{references}}
\addcontentsline{toc}{section}{References}

\hypertarget{refs}{}
\begin{CSLReferences}{1}{0}
\leavevmode\vadjust pre{\hypertarget{ref-beaudoin2018tracking}{}}%
Beaudoin, A., P. Y. Bernier, P. Villemaire, L. Guindon, and X. Jing Guo. 2018. {``Tracking Forest Attributes Across Canada Between 2001 and 2011 Using a k Nearest Neighbors Mapping Approach Applied to MODIS Imagery.''} \emph{Canadian Journal of Forest Research} 48 (1): 85--93. \url{https://doi.org/10.1139/cjfr-2017-0184}.

\leavevmode\vadjust pre{\hypertarget{ref-bivand2013applied}{}}%
Bivand, R. S., E. Pebesma, and V. Gómez-Rubio. 2013. \emph{Applied Spatial Data Analysis with r}. Use r! Springer New York.

\leavevmode\vadjust pre{\hypertarget{ref-bivand2022cran}{}}%
Bivand, Roger, and Jakub Nowosad. 2022. {``CRAN Task View: Analysis of Spatial Data,''} August. \url{https://CRAN.R-project.org/view=Spatial}.

\leavevmode\vadjust pre{\hypertarget{ref-burrough2015principles}{}}%
Burrough, Peter A, Rachael A McDonnell, and Christopher D Lloyd. 2015. \emph{Principles of Geographical Information Systems}. Oxford university press.

\leavevmode\vadjust pre{\hypertarget{ref-chiles2012geostatistics}{}}%
Chiles, JP, and P Delfiner. 2012. \emph{Geostatistics: Modeling Spatial Uncertainty}. 2nd ed. Hoboken, NJ: John Wiley \& Sons.

\leavevmode\vadjust pre{\hypertarget{ref-cressie2015statistics}{}}%
Cressie, Noel. 2015. \emph{Statistics for Spatial Data}. John Wiley \& Sons.

\leavevmode\vadjust pre{\hypertarget{ref-diggle2007model}{}}%
Diggle, P., and P. J. Ribeiro. 2007. \emph{Model-Based Geostatistics}. Springer Series in Statistics. Springer New York. \url{https://books.google.ca/books?id=qCqOm39OuFUC}.

\leavevmode\vadjust pre{\hypertarget{ref-nychka2021fields}{}}%
Douglas Nychka, Reinhard Furrer, John Paige, and Stephan Sain. 2021. {``Fields: Tools for Spatial Data.''} Boulder, CO, USA: University Corporation for Atmospheric Research. \url{https://github.com/dnychka/fieldsRPackage}.

\leavevmode\vadjust pre{\hypertarget{ref-drton2021existence}{}}%
Drton, Mathias, Satoshi Kuriki, and Peter Hoff. 2021. {``Existence and Uniqueness of the Kronecker Covariance MLE.''} \emph{The Annals of Statistics} 49 (5): 2721--54.

\leavevmode\vadjust pre{\hypertarget{ref-finley2007spbayes}{}}%
Finley, Andrew O., Sudipto Banerjee, and Bradley P. Carlin. 2007. {``{spBayes}: An {R} Package for Univariate and Multivariate Hierarchical Point-Referenced Spatial Models.''} \emph{Journal of Statistical Software} 19 (4): 1--24. \url{https://www.jstatsoft.org/article/view/v019i04}.

\leavevmode\vadjust pre{\hypertarget{ref-finley2015spbayes}{}}%
Finley, Andrew O., Sudipto Banerjee, and Alan E.Gelfand. 2015. {``{spBayes} for Large Univariate and Multivariate Point-Referenced Spatio-Temporal Data Models.''} \emph{Journal of Statistical Software} 63 (13): 1--28. \url{https://www.jstatsoft.org/article/view/v063i13}.

\leavevmode\vadjust pre{\hypertarget{ref-genton2007separable}{}}%
Genton, Marc G. 2007. {``Separable Approximations of Space-Time Covariance Matrices.''} \emph{Environmetrics} 18 (7): 681--95.

\leavevmode\vadjust pre{\hypertarget{ref-gramacy2016lagp}{}}%
Gramacy, Robert B. 2016. {``laGP: Large-Scale Spatial Modeling via Local Approximate Gaussian Processes in r.''} \emph{Journal of Statistical Software} 72 (1): 1--46. \url{https://doi.org/10.18637/jss.v072.i01}.

\leavevmode\vadjust pre{\hypertarget{ref-koch2020computationally}{}}%
Koch, Dean, Subhash Lele, and Mark A Lewis. 2020. {``Computationally Simple Anisotropic Lattice Covariograms.''} \emph{Environmental and Ecological Statistics} 27 (4): 665--88.

\leavevmode\vadjust pre{\hypertarget{ref-koch2021signature}{}}%
Koch, Dean, Mark A Lewis, and Subhash Lele. 2021. {``The Signature of Endemic Populations in the Spread of Mountain Pine Beetle Outbreaks.''} \emph{Bulletin of Mathematical Biology} 83 (6): 1--24.

\leavevmode\vadjust pre{\hypertarget{ref-koch2020unifying}{}}%
Koch, Dean, Mark Lewis, and Subhash Lele. 2020. {``A Unifying Theory for Two-Dimensional Spatial Redistribution Kernels with Applications in Population Spread Modelling.''} \emph{Journal of the Royal Society Interface} 17 (170): 20200434.

\leavevmode\vadjust pre{\hypertarget{ref-lindgren2015bayesian}{}}%
Lindgren, Finn, and Håvard Rue. 2015. {``Bayesian Spatial Modelling with r-INLA.''} \emph{Journal of Statistical Software} 63: 1--25.

\leavevmode\vadjust pre{\hypertarget{ref-lindgren2011explicit}{}}%
Lindgren, Finn, Håvard Rue, and Johan Lindström. 2011. {``An Explicit Link Between Gaussian Fields and Gaussian Markov Random Fields: The Stochastic Partial Differential Equation Approach.''} \emph{Journal of the Royal Statistical Society: Series B (Statistical Methodology)} 73 (4): 423--98.

\leavevmode\vadjust pre{\hypertarget{ref-martin1979subclass}{}}%
Martin, RJ. 1979. {``A Subclass of Lattice Processes Applied to a Problem in Planar Sampling.''} \emph{Biometrika} 66 (2): 209--17.

\leavevmode\vadjust pre{\hypertarget{ref-nychka2016latticekrig}{}}%
Nychka, Douglas, Dorit Hammerling, Stephan Sain, and Nathan Lenssen. 2016. {``LatticeKrig: Multiresolution Kriging Based on Markov Random Fields.''} Boulder, CO, USA: University Corporation for Atmospheric Research. \url{https://doi.org/10.5065/D6HD7T1R}.

\leavevmode\vadjust pre{\hypertarget{ref-paciorek2015biggp}{}}%
Paciorek, Christopher J., Benjamin Lipshitz, Wei Zhuo, Prabhat, Cari G. Kaufman, and Rollin C. Thomas. 2015. {``Parallelizing Gaussian Process Calculations in {R}.''} \emph{Journal of Statistical Software} 63 (10): 1--23. \url{https://doi.org/10.18637/jss.v063.i10}.

\leavevmode\vadjust pre{\hypertarget{ref-pebesma2022meuse}{}}%
Pebesma, Edzer. 2022. {``The Meuse Data Set: A Brief Tutorial for the Gstat r Package.''} ViennaR.

\leavevmode\vadjust pre{\hypertarget{ref-pebesma2004gstat}{}}%
Pebesma, Edzer J. 2004. {``Multivariable Geostatistics in {S}: The Gstat Package.''} \emph{Computers \& Geosciences} 30: 683--91.

\leavevmode\vadjust pre{\hypertarget{ref-pebesma2005sp}{}}%
Pebesma, Edzer J., and Roger S. Bivand. 2005. {``Classes and Methods for Spatial Data in {R}.''} \emph{R News} 5 (2): 9--13. \url{https://CRAN.R-project.org/doc/Rnews/}.

\leavevmode\vadjust pre{\hypertarget{ref-rasmussen2006gaussian}{}}%
Rasmussen, Carl Edward, and Christopher KI Williams. 2006. \emph{Gaussian Processes for Machine Learning}. Cambridge, MA: MIT press.

\leavevmode\vadjust pre{\hypertarget{ref-ribeiro1999splus}{}}%
Ribeiro Jr, Paulo J, and Peter J Diggle. 1999. {``geoS: A Geostatistical Library for s-PLUS.''} \emph{Technical Report}, 1--6.

\leavevmode\vadjust pre{\hypertarget{ref-schlather2015randomfields}{}}%
Schlather, Martin, Alexander Malinowski, Peter J. Menck, Marco Oesting, and Kirstin Strokorb. 2015. {``Analysis, Simulation and Prediction of Multivariate Random Fields with Package {RandomFields}.''} \emph{Journal of Statistical Software} 63 (8): 1--25. \url{http://www.jstatsoft.org/v63/i08/}.

\leavevmode\vadjust pre{\hypertarget{ref-van2000ubiquitous}{}}%
Van Loan, Charles F. 2000. {``The Ubiquitous {K}ronecker Product.''} \emph{J Comput Appl Math} 123 (1): 85--100.

\leavevmode\vadjust pre{\hypertarget{ref-zammit2021frk}{}}%
Zammit-Mangion, Andrew, and Noel Cressie. 2021. {``FRK: An r Package for Spatial and Spatio-Temporal Prediction with Large Datasets.''} \emph{Journal of Statistical Software} 98 (4): 1--48.

\end{CSLReferences}

\bibliography{RJreferences.bib}

\address{%
Dean Koch\\
University of Alberta\\%
Department of Mathematical and Statistical Sciences\\ 11324 89 Ave NW, Edmonton, AB, Canada, T6G 2J5.\\
%
\url{https://github.com/deankoch/pkern}\\%
\textit{ORCiD: \href{https://orcid.org/0000-0002-8849-859X}{0000-0002-8849-859X}}\\%
\href{mailto:dkoch@ualberta.ca}{\nolinkurl{dkoch@ualberta.ca}}%
}

\address{%
Subhash Lele\\
University of Alberta\\%
Department of Mathematical and Statistical Sciences\\ 11324 89 Ave NW, Edmonton, AB, Canada, T6G 2J5.\\
%
%
%
\href{mailto:slele@ualberta.ca}{\nolinkurl{slele@ualberta.ca}}%
}

\address{%
Robert Crabtree\\
Yellowstone Ecological Research Center\\%
Bozeman, MT\\
%
%
%
\href{mailto:crabtree@yellowstoneresearch.org}{\nolinkurl{crabtree@yellowstoneresearch.org}}%
}
